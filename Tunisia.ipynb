{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import ensemble, metrics, model_selection, naive_bayes\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"SampleSubmission.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "train = pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1436, 3), (620, 2), (620, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train.shape , test.shape , sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AASHwXxg</td>\n",
       "      <td>Mwangonde: Khansala wachinyamata Akamati achi...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AGoFySzn</td>\n",
       "      <td>MCP siidakhutire ndi kalembera Chipani cha Ma...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text     Label\n",
       "0  ID_AASHwXxg   Mwangonde: Khansala wachinyamata Akamati achi...  POLITICS\n",
       "1  ID_AGoFySzn   MCP siidakhutire ndi kalembera Chipani cha Ma...  POLITICS"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({' ': 335,\n",
       "         'M': 20,\n",
       "         'w': 67,\n",
       "         'a': 374,\n",
       "         'n': 189,\n",
       "         'g': 34,\n",
       "         'o': 113,\n",
       "         'd': 112,\n",
       "         'e': 100,\n",
       "         ':': 3,\n",
       "         'K': 7,\n",
       "         'h': 87,\n",
       "         's': 55,\n",
       "         'l': 79,\n",
       "         'c': 46,\n",
       "         'i': 237,\n",
       "         'y': 50,\n",
       "         'm': 105,\n",
       "         't': 83,\n",
       "         'A': 9,\n",
       "         'k': 104,\n",
       "         'r': 50,\n",
       "         ',': 13,\n",
       "         'b': 33,\n",
       "         'z': 52,\n",
       "         'u': 125,\n",
       "         '.': 20,\n",
       "         'L': 3,\n",
       "         'p': 46,\n",
       "         'f': 6,\n",
       "         'D': 3,\n",
       "         'I': 4,\n",
       "         'E': 2,\n",
       "         'S': 3,\n",
       "         'B': 2,\n",
       "         'N': 13,\n",
       "         'J': 1,\n",
       "         'W': 2,\n",
       "         'C': 6,\n",
       "         'P': 4,\n",
       "         'T': 1,\n",
       "         '2': 2,\n",
       "         '7': 1,\n",
       "         'j': 5,\n",
       "         '\\n': 7,\n",
       "         '?': 6,\n",
       "         'v': 1,\n",
       "         'V': 1,\n",
       "         'R': 1,\n",
       "         '(': 1,\n",
       "         ')': 1,\n",
       "         '1': 1,\n",
       "         'Z': 2})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# [x  for x in string.ascii_lowercase]\n",
    "\n",
    "for x in string.ascii_lowercase:\n",
    "    new_df[x] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>...</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13P0QT0</td>\n",
       "      <td>3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKCLXCJ</td>\n",
       "      <td>cha3eb fey9elkoum menghir ta7ayoul ou kressi</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1TVXIJ</td>\n",
       "      <td>bereau degage nathef ya slim walahi ya7chiw fi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0TTYY8</td>\n",
       "      <td>ak slouma</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68DX797</td>\n",
       "      <td>entom titmanou lina a7na 3iid moubarik a7na ch...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  label  a  b  c  \\\n",
       "0  13P0QT0  3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...     -1  0  0  0   \n",
       "1  SKCLXCJ       cha3eb fey9elkoum menghir ta7ayoul ou kressi     -1  0  0  0   \n",
       "2  V1TVXIJ  bereau degage nathef ya slim walahi ya7chiw fi...     -1  0  0  0   \n",
       "3  U0TTYY8                                          ak slouma      1  0  0  0   \n",
       "4  68DX797  entom titmanou lina a7na 3iid moubarik a7na ch...     -1  0  0  0   \n",
       "\n",
       "   d  e  f  g  ...  q  r  s  t  u  v  w  x  y  z  \n",
       "0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "1  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "2  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "3  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "4  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i ,j in Counter(train['text'][0]).items():\n",
    "#     new_df.loc[0][i] = j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(train.shape[]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13P0QT0</td>\n",
       "      <td>3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKCLXCJ</td>\n",
       "      <td>cha3eb fey9elkoum menghir ta7ayoul ou kressi</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1TVXIJ</td>\n",
       "      <td>bereau degage nathef ya slim walahi ya7chiw fi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0TTYY8</td>\n",
       "      <td>ak slouma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68DX797</td>\n",
       "      <td>entom titmanou lina a7na 3iid moubarik a7na ch...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  label\n",
       "0  13P0QT0  3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...     -1\n",
       "1  SKCLXCJ       cha3eb fey9elkoum menghir ta7ayoul ou kressi     -1\n",
       "2  V1TVXIJ  bereau degage nathef ya slim walahi ya7chiw fi...     -1\n",
       "3  U0TTYY8                                          ak slouma      1\n",
       "4  68DX797  entom titmanou lina a7na 3iid moubarik a7na ch...     -1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample_size  = int(train[train['label']== -1].shape[0]*0.8)\n",
    "# train_2 = train[train['label']== 1].sample(5000, replace = True)\n",
    "# train_1 = train[train['label']== -1].sample(5000, replace = True)\n",
    "# train = train[train['label'] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train  , train_2 , train_1]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-36f04b6ce127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot dist for labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnt_srs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_srs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt_srs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "# plot dist for labels\n",
    "cnt_srs = train['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Label', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_mapping_dict = {0:0, 1:1, -1:2}\n",
    "train_y = train['label'].map(author_mapping_dict)\n",
    "train['label'] = train['label'].map(author_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape\n",
    "y = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot dist for labels\n",
    "cnt_srs = train['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Label', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z =0\n",
    "# for i in range(20):\n",
    "#     try:\n",
    "#         print(train[train['label'] == -1].loc[i]['text'])\n",
    "#     z = z+1\n",
    "#     if z ==10:\n",
    "#         break\n",
    "#     print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that the dataset is not equally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :  0\n",
      "nheb nkollek ana mathimni fi tunis ken ca w madhabia timchi 3la rohek milli ritnek ma rana khir\n",
      "slim slim slim slim\n",
      "salim ben hamidane\n",
      "eli ychouf fihom zouz frèret ydez like\n",
      "slm brabi kifeh enajmo enbadlo meken alinti5ab\n",
      "\n",
      "\n",
      "Label :  1\n",
      "ak slouma\n",
      "hhhhhhhh blidaa minik ba3d doussieet athika ilkol 8nayit a7na wil 9amar jiran\n",
      "wahdek big boss\n",
      "3omra ma9boula si slim\n",
      "admin kifech najem nwali membre fi partie politique de mr moncef marzouki\n",
      "\n",
      "\n",
      "Label :  2\n",
      "3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi ou 3sbaaaaaaaaaaaaaaaaaaaaaaaaaaa le ca\n",
      "cha3eb fey9elkoum menghir ta7ayoul ou kressi\n",
      "bereau degage nathef ya slim walahi ya7chiw fih jma3a lem3amel 3lihom walah kit jib messi lana3mlou chay 7amlet nathafa fil bureaux ca jam3iya 3ari9a mel 3am 94 bdet da5la fi 7it choufelna hal mochkla belehi te5na9na mel fada tous les équipe mergine fina ken jit kifek walah maye5lsouch wi3adiw 3am jaych bech yetrabaw elkoura fi se9ik enti en9eth jam3iya ya slim wna3ref tnajim ta3melha\n",
      "entom titmanou lina a7na 3iid moubarik a7na cha3b lmanyik lf9iir lmit5alim eli mahouch korza kifkom y3anbou t7iinkom\n",
      "9arwwwwii yhbb 3alaa bouwahh la7niynn 5hndhawii\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets see review for 5 texts\n",
    "grouped_df = train.groupby('label')\n",
    "for label, sent in grouped_df:\n",
    "    print(\"Label : \", label)\n",
    "    cnt = 0\n",
    "    for ind, row in sent.iterrows():\n",
    "        print(row[\"text\"])\n",
    "        cnt += 1\n",
    "        if cnt == 5:\n",
    "            break\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall('a' , train['text'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some features\n",
    "import re\n",
    "train_df = train.copy()\n",
    "test_df = test.copy()\n",
    "## Number of words in the text ##\n",
    "# train_df[\"num_words\"] = train_df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "# test_df[\"num_words\"] = test_df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "## Number of unique words in the text ##\n",
    "train_df[\"num_unique_words\"] = train_df[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test_df[\"num_unique_words\"] = test_df[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "## Number of characters in the text ##\n",
    "train_df[\"num_chars\"] = train_df[\"text\"].apply(lambda x: len(str(x)))\n",
    "test_df[\"num_chars\"] = test_df[\"text\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "\n",
    "# num of a\n",
    "train_df['num_a_found'] = train['text'].apply(lambda x: len([re.findall(r'[a]+' , w) for w in  x]))\n",
    "test_df['num_a_found'] = test['text'].apply(lambda x: len([re.findall(r'[a]+' , w) for w in  x]))\n",
    "\n",
    "\n",
    "# len of words with more a\n",
    "def getNumA(text ):\n",
    "    return len(re.findall(r'[a]+' , text))\n",
    "train_df['a_found'] = train['text'].apply(getNumA)\n",
    "test_df['a_found'] = test['text'].apply(getNumA)\n",
    "\n",
    "\n",
    "# len of words with more \n",
    "def getNumChar(text , cha ):\n",
    "    return len(re.findall(cha , text))\n",
    "\n",
    "for each_char in string.ascii_lowercase:\n",
    "    train_df[f'{each_char}_char'] = train['text'].apply(lambda x : getNumChar(x , each_char))\n",
    "    test_df[f'{each_char}_char'] = test['text'].apply(lambda x : getNumChar(x , each_char))\n",
    "\n",
    "# found len of numbers\n",
    "train_df['digit_count'] = train['text'].apply(lambda x: len([w for w in re.findall(r'[0-9]+', str(x))]))\n",
    "test_df['digit_count'] = test['text'].apply(lambda x: len([w for w in re.findall(r'[0-9]+', str(x))]))\n",
    "\n",
    "# sum all digits\n",
    "train_df['sum_digit'] = train['text'].apply(lambda x: sum([int(w) for w in re.findall(r'[0-9]+', str(x))]))\n",
    "test_df['sum_digit'] = test['text'].apply(lambda x: sum([int(w) for w in re.findall(r'[0-9]+', str(x))]))\n",
    "\n",
    "# average digits\n",
    "train_df['average_digit'] = train['text'].apply(lambda x: np.mean([int(w) for w in re.findall(r'[0-9]+', str(x))])).fillna(value =0)\n",
    "test_df['average_digit'] = test['text'].apply(lambda x: np.mean([int(w) for w in re.findall(r'[0-9]+', str(x))])).fillna(value =0)\n",
    "\n",
    "\n",
    "# ## Number of stopwords in the text ##\n",
    "# train_df[\"num_stopwords\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "# test_df[\"num_stopwords\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "\n",
    "## Number of punctuations in the text ##\n",
    "# train_df[\"num_punctuations\"] =train_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "# test_df[\"num_punctuations\"] =test_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "## Number of title case words in the text ##\n",
    "# train_df[\"num_words_upper\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "# test_df[\"num_words_upper\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "## Number of title case words in the text ##\n",
    "# train_df[\"num_words_title\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "# test_df[\"num_words_title\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "## Average length of the words in the text ##\n",
    "train_df[\"mean_word_len\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"mean_word_len\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 37), (30000, 36))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape , test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_a_found</th>\n",
       "      <th>a_found</th>\n",
       "      <th>a_char</th>\n",
       "      <th>b_char</th>\n",
       "      <th>c_char</th>\n",
       "      <th>...</th>\n",
       "      <th>u_char</th>\n",
       "      <th>v_char</th>\n",
       "      <th>w_char</th>\n",
       "      <th>x_char</th>\n",
       "      <th>y_char</th>\n",
       "      <th>z_char</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>sum_digit</th>\n",
       "      <th>average_digit</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13P0QT0</td>\n",
       "      <td>3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKCLXCJ</td>\n",
       "      <td>cha3eb fey9elkoum menghir ta7ayoul ou kressi</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1TVXIJ</td>\n",
       "      <td>bereau degage nathef ya slim walahi ya7chiw fi...</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>387</td>\n",
       "      <td>387</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>202</td>\n",
       "      <td>8.782609</td>\n",
       "      <td>5.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0TTYY8</td>\n",
       "      <td>ak slouma</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68DX797</td>\n",
       "      <td>entom titmanou lina a7na 3iid moubarik a7na ch...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  label  \\\n",
       "0  13P0QT0  3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...      2   \n",
       "1  SKCLXCJ       cha3eb fey9elkoum menghir ta7ayoul ou kressi      2   \n",
       "2  V1TVXIJ  bereau degage nathef ya slim walahi ya7chiw fi...      2   \n",
       "3  U0TTYY8                                          ak slouma      1   \n",
       "4  68DX797  entom titmanou lina a7na 3iid moubarik a7na ch...      2   \n",
       "\n",
       "   num_unique_words  num_chars  num_a_found  a_found  a_char  b_char  c_char  \\\n",
       "0                 8         84           84        4      49       2       1   \n",
       "1                 6         44           44        3       3       1       1   \n",
       "2                57        387          387       52      52       7       8   \n",
       "3                 2          9            9        2       2       0       0   \n",
       "4                16        116          116       13      13       3       2   \n",
       "\n",
       "   ...  u_char  v_char  w_char  x_char  y_char  z_char  digit_count  \\\n",
       "0  ...       2       0       0       0       0       0            2   \n",
       "1  ...       3       0       0       0       2       0            3   \n",
       "2  ...       9       0       8       1       9       0           23   \n",
       "3  ...       1       0       0       0       0       0            0   \n",
       "4  ...       4       0       0       0       2       1            8   \n",
       "\n",
       "   sum_digit  average_digit  mean_word_len  \n",
       "0          6       3.000000       7.500000  \n",
       "1         19       6.333333       6.500000  \n",
       "2        202       8.782609       5.062500  \n",
       "3          0       0.000000       4.000000  \n",
       "4         44       5.500000       5.882353  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['num_words'].loc[train_df['num_words']>30] = 30 #truncation for better visuals\n",
    "# plt.figure(figsize=(12,8))\n",
    "# sns.violinplot(x='label', y='num_words', data=train_df)\n",
    "# plt.xlabel('Label ', fontsize=12)\n",
    "# plt.ylabel('Number of words in text', fontsize=12)\n",
    "# plt.title(\"Number of words by label\", fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['num_punctuations'].loc[train_df['num_punctuations']>5] = 5 #truncation for better visuals\n",
    "# plt.figure(figsize=(12,8))\n",
    "# sns.violinplot(x='label', y='num_punctuations', data=train_df)\n",
    "# plt.xlabel('Label', fontsize=12)\n",
    "# plt.ylabel('Number of puntuations in text', fontsize=12)\n",
    "# plt.title(\"Number of punctuations by label\", fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these guys basely do punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### recompute the trauncated variables again ###\n",
    "# train_df[\"num_words\"] = train_df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "# test_df[\"num_words\"] = test_df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "# train_df[\"mean_word_len\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "# test_df[\"mean_word_len\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "cols_to_drop = ['ID', 'text']\n",
    "train_X = train_df.drop(cols_to_drop+['label'], axis=1)\n",
    "test_X = test_df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 34), (30000, 34), (70000,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape   , test_X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  0\n",
       "text                0\n",
       "label               0\n",
       "num_unique_words    0\n",
       "num_chars           0\n",
       "num_a_found         0\n",
       "a_found             0\n",
       "a_char              0\n",
       "b_char              0\n",
       "c_char              0\n",
       "d_char              0\n",
       "e_char              0\n",
       "f_char              0\n",
       "g_char              0\n",
       "h_char              0\n",
       "i_char              0\n",
       "j_char              0\n",
       "k_char              0\n",
       "l_char              0\n",
       "m_char              0\n",
       "n_char              0\n",
       "o_char              0\n",
       "p_char              0\n",
       "q_char              0\n",
       "r_char              0\n",
       "s_char              0\n",
       "t_char              0\n",
       "u_char              0\n",
       "v_char              0\n",
       "w_char              0\n",
       "x_char              0\n",
       "y_char              0\n",
       "z_char              0\n",
       "digit_count         0\n",
       "sum_digit           0\n",
       "average_digit       0\n",
       "mean_word_len       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, seed_val=2017, child=1, colsample=0.3):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "#     param['eta'] = 0.1\n",
    "#     param['max_depth'] = 3\n",
    "#     param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "#     param['min_child_weight'] = child\n",
    "#     param['subsample'] = 0.8\n",
    "#     param['colsample_bytree'] = colsample\n",
    "#     param['seed'] = seed_val\n",
    "    num_rounds = 2000\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n",
    "    if test_X2 is not None:\n",
    "        xgtest2 = xgb.DMatrix(test_X2)\n",
    "        pred_test_y2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n",
    "    return pred_test_y, pred_test_y2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "def runCat(train_X, train_y, test_X, test_y, test_X2):\n",
    "    cat = CatBoostClassifier(n_estimators=300 , logging_level = 'Silent')\n",
    "    cat.fit(train_X, train_y)\n",
    "    pred_test_y = cat.predict_proba(test_X)\n",
    "    pred_test_y2 = cat.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(CatBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv scores :  [0.6736550290773062, 0.6652315194071359, 0.6641191704928671, 0.6656650607027272, 0.6600551704123765]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "cv_scores = []\n",
    "train_y = y.copy()\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, cat_clf = runCat(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    \n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876428571428571"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(val_y , cat_clf.predict(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "def runMNB(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def runxgb(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model =XGBClassifier(n_estimators=400)\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "def runlgb(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model =LGBMClassifier(n_estimators=400)\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "\n",
    "def runLog(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def runBag(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = BaggingClassifier(LogisticRegression())\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def runran(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv scores :  [33.28797927832355, 33.25605608892411, 33.305397198059694, 33.31289738545583, 33.354886838733975]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "cv_scores = []\n",
    "train_y = y.copy()\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, mnb_clf = runMNB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    \n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.96952\ttest-mlogloss:0.97505\n",
      "[50]\ttrain-mlogloss:0.58368\ttest-mlogloss:0.67746\n",
      "[100]\ttrain-mlogloss:0.53025\ttest-mlogloss:0.67431\n",
      "[150]\ttrain-mlogloss:0.48742\ttest-mlogloss:0.67411\n",
      "[167]\ttrain-mlogloss:0.47750\ttest-mlogloss:0.67483\n",
      "cv scores :  [0.6732856814273234]\n"
     ]
    }
   ],
   "source": [
    "# metrics.accuracy_score(val_y , model.predict(val_X))\n",
    "\n",
    "\n",
    "test_X['sum_digit'] =test_X['sum_digit'].astype('float64')\n",
    "train_X['sum_digit'] =train_X['sum_digit'].astype('float64')\n",
    "def do(train_X,test_X,train_y):\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([train_X.shape[0], 3])\n",
    "    for dev_index, val_index in kf.split(train_X):\n",
    "        dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, test_X, seed_val=0, colsample=0.7)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "        cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "        break\n",
    "    print(\"cv scores : \", cv_scores)\n",
    "    return pred_full_test/5\n",
    "result = do(train_X,test_X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit transform the tfidf vectorizer ###\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "full_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  [0.586658064286428, 0.5886109239195056, 0.5793259782895569, 0.5849762292230126, 0.578961574006492]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, mnb_clf = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", cv_scores)\n",
    "pred_full_test = pred_full_test / 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7558822268889556"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(val_y , mnb_clf.predict(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:55:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:00:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Mean cv score :  [0.5530430632050772, 0.5623394796413566, 0.5579973989924134]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=100)\n",
    "cv_scores = []\n",
    "pred_full_testx = 0\n",
    "pred_trainx = np.zeros([train_df.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y,cat_clf = runxgb(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", cv_scores)\n",
    "pred_full_test = pred_full_test / 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(train_tfidf[: , 4:10].todense()).apply(sum , axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.945453\n",
       "1    1.237079\n",
       "2    0.772525\n",
       "3    0.397807\n",
       "4    1.429251\n",
       "5    1.166190\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tfidf.shape[1]\n",
    "\n",
    "for i in range(0 , 188885 , 3000):\n",
    "    if (i+3000) > 188885:\n",
    "        train_X[f\"Sum_{i}\"] = pd.DataFrame(train_tfidf[: , i:188885 -i].todense()).apply(sum , axis =1)\n",
    "        test_X[f\"Sum_{i}\"] = pd.DataFrame(test_tfidf[: , i:188885 -i].todense()).apply(sum , axis =1)\n",
    "        break\n",
    "    train_X[f\"Sum_{i}\"] = pd.DataFrame(train_tfidf[: , i:i+3000].todense()).apply(sum , axis =1)\n",
    "    test_X[f\"Sum_{i}\"] = pd.DataFrame(test_tfidf[: , i:i+3000].todense()).apply(sum , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_a_found</th>\n",
       "      <th>a_found</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>sum_digit</th>\n",
       "      <th>average_digit</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>Sum_0</th>\n",
       "      <th>Sum_3000</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum_159000</th>\n",
       "      <th>Sum_162000</th>\n",
       "      <th>Sum_165000</th>\n",
       "      <th>Sum_168000</th>\n",
       "      <th>Sum_171000</th>\n",
       "      <th>Sum_174000</th>\n",
       "      <th>Sum_177000</th>\n",
       "      <th>Sum_180000</th>\n",
       "      <th>Sum_183000</th>\n",
       "      <th>Sum_186000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.864614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>387</td>\n",
       "      <td>387</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>202.0</td>\n",
       "      <td>8.782609</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>0.305839</td>\n",
       "      <td>0.098294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274523</td>\n",
       "      <td>0.172017</td>\n",
       "      <td>0.158682</td>\n",
       "      <td>0.265951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.299007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_unique_words  num_chars  num_a_found  a_found  digit_count  sum_digit  \\\n",
       "0                 8         84           84        4            2        6.0   \n",
       "1                 6         44           44        3            3       19.0   \n",
       "2                57        387          387       52           23      202.0   \n",
       "3                 2          9            9        2            0        0.0   \n",
       "4                16        116          116       13            8       44.0   \n",
       "\n",
       "   average_digit  mean_word_len     Sum_0  Sum_3000  ...  Sum_159000  \\\n",
       "0       3.000000       7.500000  0.000000  0.864614  ...         0.0   \n",
       "1       6.333333       6.500000  0.000000  0.000000  ...         0.0   \n",
       "2       8.782609       5.062500  0.305839  0.098294  ...         0.0   \n",
       "3       0.000000       4.000000  0.000000  0.000000  ...         0.0   \n",
       "4       5.500000       5.882353  0.000000  0.267316  ...         0.0   \n",
       "\n",
       "   Sum_162000  Sum_165000  Sum_168000  Sum_171000  Sum_174000  Sum_177000  \\\n",
       "0    0.000000    0.000000    0.000000    0.000000         0.0         0.0   \n",
       "1    0.000000    0.000000    0.000000    0.000000         0.0         0.0   \n",
       "2    0.274523    0.172017    0.158682    0.265951         0.0         0.0   \n",
       "3    0.000000    0.000000    0.000000    0.000000         0.0         0.0   \n",
       "4    0.000000    0.000000    0.000000    0.299007         0.0         0.0   \n",
       "\n",
       "   Sum_180000  Sum_183000  Sum_186000  \n",
       "0    0.000000         0.0           0  \n",
       "1    0.000000         0.0           0  \n",
       "2    0.172017         0.0           0  \n",
       "3    0.000000         0.0           0  \n",
       "4    0.000000         0.0           0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  [0.557901405211494, 0.5502610889054851, 0.539469462069484, 0.554992017633521, 0.5486286370157062]\n"
     ]
    }
   ],
   "source": [
    "tfcount_vec = CountVectorizer( ngram_range=(1,1))\n",
    "tfcount_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\n",
    "train_tfcount = tfcount_vec.transform(train_df['text'].values.tolist())\n",
    "test_tfcount = tfcount_vec.transform(test_df['text'].values.tolist())\n",
    "\n",
    "\n",
    "\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfcount[dev_index], train_tfcount[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, model = runLog(dev_X, dev_y, val_X, val_y, test_tfcount)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", cv_scores)\n",
    "pred_full_test = pred_full_test / 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0 , 188885 , 4000):\n",
    "    if (i+3000) > 188885:\n",
    "        train_X[f\"Count_{i}\"] = pd.DataFrame(train_tfcount[: , i:188885 -i].todense()).apply(sum , axis =1)\n",
    "        test_X[f\"Count_{i}\"] = pd.DataFrame(test_tfcount[: , i:188885 -i].todense()).apply(sum , axis =1)\n",
    "        break\n",
    "    train_X[f\"Count_{i}\"] = pd.DataFrame(train_tfcount[: , i:i+4000].todense()).apply(sum , axis =1)\n",
    "    test_X[f\"Count_{i}\"] = pd.DataFrame(test_tfcount[: , i:i+4000].todense()).apply(sum , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this csv\n",
    "train_X.to_csv(\"trained.csv\" , index = False)\n",
    "test_X.to_csv(\"tested.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_a_found</th>\n",
       "      <th>a_found</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>sum_digit</th>\n",
       "      <th>average_digit</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>Sum_0</th>\n",
       "      <th>Sum_3000</th>\n",
       "      <th>...</th>\n",
       "      <th>Count_152000</th>\n",
       "      <th>Count_156000</th>\n",
       "      <th>Count_160000</th>\n",
       "      <th>Count_164000</th>\n",
       "      <th>Count_168000</th>\n",
       "      <th>Count_172000</th>\n",
       "      <th>Count_176000</th>\n",
       "      <th>Count_180000</th>\n",
       "      <th>Count_184000</th>\n",
       "      <th>Count_188000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.864614</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>387</td>\n",
       "      <td>387</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>202.0</td>\n",
       "      <td>8.782609</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>0.305839</td>\n",
       "      <td>0.098294</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_unique_words  num_chars  num_a_found  a_found  digit_count  sum_digit  \\\n",
       "0                 8         84           84        4            2        6.0   \n",
       "1                 6         44           44        3            3       19.0   \n",
       "2                57        387          387       52           23      202.0   \n",
       "3                 2          9            9        2            0        0.0   \n",
       "4                16        116          116       13            8       44.0   \n",
       "\n",
       "   average_digit  mean_word_len     Sum_0  Sum_3000  ...  Count_152000  \\\n",
       "0       3.000000       7.500000  0.000000  0.864614  ...             0   \n",
       "1       6.333333       6.500000  0.000000  0.000000  ...             0   \n",
       "2       8.782609       5.062500  0.305839  0.098294  ...             0   \n",
       "3       0.000000       4.000000  0.000000  0.000000  ...             0   \n",
       "4       5.500000       5.882353  0.000000  0.267316  ...             0   \n",
       "\n",
       "   Count_156000  Count_160000  Count_164000  Count_168000  Count_172000  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             2             3             1             1             3   \n",
       "3             0             0             0             0             0   \n",
       "4             1             0             0             0             1   \n",
       "\n",
       "   Count_176000  Count_180000  Count_184000  Count_188000  \n",
       "0             0             0             0             0  \n",
       "1             0             0             0             0  \n",
       "2             0             1             0             0  \n",
       "3             0             0             0             0  \n",
       "4             0             0             0             0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv(\"trained.csv\")\n",
    "te = pd.read_csv(\"tested.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "cv scores :  [0.6574205660722717]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "cv_scores = []\n",
    "train_y = y.copy()\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([tr.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(tr.fillna(0)):\n",
    "    dev_X, val_X = tr.loc[dev_index], tr.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, reg = runxgb(dev_X, dev_y, val_X, val_y, te.fillna(0))\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    break\n",
    "    \n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984285714285714"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(val_y , reg.predict(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.96690\ttest-mlogloss:0.97218\n",
      "[50]\ttrain-mlogloss:0.55393\ttest-mlogloss:0.65281\n",
      "[100]\ttrain-mlogloss:0.50592\ttest-mlogloss:0.64908\n",
      "[150]\ttrain-mlogloss:0.47081\ttest-mlogloss:0.64904\n",
      "[163]\ttrain-mlogloss:0.46361\ttest-mlogloss:0.64886\n",
      "cv scores :  [0.6485469856555242]\n"
     ]
    }
   ],
   "source": [
    "result = do(tr,te,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 35\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(full_tfidf)\n",
    "train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "    \n",
    "train_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "test_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "train_df = pd.concat([train_df, train_svd], axis=1)\n",
    "test_df = pd.concat([test_df, test_svd], axis=1)\n",
    "del full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit transform the count vectorizer ###\n",
    "tfidf_vec = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "tfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  [0.7988704652608264, 0.7935498620202777, 0.7748654358115187, 0.8140000881449576, 0.7795205406176805]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, mnb_clf = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", cv_scores)\n",
    "pred_full_test = pred_full_test / 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add the predictions as new features #\n",
    "train_df[\"nb_cvec_0\"] = pred_train[:,0] + (pred_train[:,1]+pred_train[:,2])/2\n",
    "train_df[\"nb_cvec_1\"] = pred_train[:,1]\n",
    "train_df[\"nb_cvec_2\"] = pred_train[:,2]\n",
    "test_df[\"nb_cvec_0\"] = pred_full_test[:,0]+(pred_full_test[:,1]+pred_full_test[:,2])/2\n",
    "test_df[\"nb_cvec_1\"] = pred_full_test[:,1]\n",
    "test_df[\"nb_cvec_2\"] = pred_full_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  [0.7460848105897775, 0.7384972544416037, 0.7349328681585339, 0.7382601015773109, 0.7317851214135237]\n"
     ]
    }
   ],
   "source": [
    "### Fit transform the tfidf vectorizer ###\n",
    "tfidf_vec = CountVectorizer(ngram_range=(1,1), analyzer='char')\n",
    "tfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n",
    "\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, mnb_clf = runLog(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", cv_scores)\n",
    "pred_full_test = pred_full_test / 5.\n",
    "\n",
    "# add the predictions as new features #\n",
    "train_df[\"nb_cvec_char_0\"] = pred_train[:,0] +(pred_train[:,1]+pred_train[:,2])/2\n",
    "train_df[\"nb_cvec_char_1\"] = pred_train[:,1]\n",
    "train_df[\"nb_cvec_char_2\"] = pred_train[:,2]\n",
    "test_df[\"nb_cvec_char_0\"] = pred_full_test[:,0]+(pred_full_test[:,1]+pred_full_test[:,2])/2\n",
    "test_df[\"nb_cvec_char_1\"] = pred_full_test[:,1]\n",
    "test_df[\"nb_cvec_char_2\"] = pred_full_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  [0.7626428571428572, 0.7713571428571429, 0.7759285714285714, 0.7692857142857142, 0.7661428571428571]\n"
     ]
    }
   ],
   "source": [
    "### Fit transform the tfidf vectorizer ###\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,1), analyzer='word')\n",
    "full_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n",
    "\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, mnb_clf = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.accuracy_score(val_y, getVal(pd.DataFrame(pred_val_y))))\n",
    "print(\"Mean cv score : \",cv_scores)\n",
    "pred_full_test = pred_full_test / 5.0\n",
    "\n",
    "# add the predictions as new features #\n",
    "train_df[\"nb_tfidf_char_0\"] = pred_train[:,0]\n",
    "train_df[\"nb_tfidf_char_1\"] = pred_train[:,1]\n",
    "train_df[\"nb_tfidf_char_2\"] = pred_train[:,2]\n",
    "test_df[\"nb_tfidf_char_0\"] = pred_full_test[:,0]\n",
    "test_df[\"nb_tfidf_char_1\"] = pred_full_test[:,1]\n",
    "test_df[\"nb_tfidf_char_2\"] = pred_full_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp =6\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='randomized' , n_iter=10, random_state=42)\n",
    "svd_obj.fit(full_tfidf)\n",
    "train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "    \n",
    "train_svd.columns = ['svd_char_'+str(i) for i in range(n_comp)]\n",
    "test_svd.columns = ['svd_char_'+str(i) for i in range(n_comp)]\n",
    "train_df = pd.concat([train_df, train_svd], axis=1)\n",
    "test_df = pd.concat([test_df, test_svd], axis=1)\n",
    "del full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['ID', 'text']\n",
    "train_df = train_df.drop(cols_to_drop+['label'], axis=1)\n",
    "test_df = test_df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 58), (70000,), (30000, 58))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape , train_y.shape ,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\n",
    "# cv_scores = []\n",
    "# pred_full_testdx = 0\n",
    "# pred_train = np.zeros([train_df.shape[0], 3])\n",
    "# for dev_index, val_index in kf.split(train_X):\n",
    "#     dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "#     dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "#     pred_val_y, pred_test_y, xgb = runXGB(dev_X, dev_y, val_X, val_y, test_X, seed_val=0, colsample=0.7)\n",
    "#     pred_full_testdx = pred_full_testdx + pred_test_y\n",
    "#     pred_train[val_index,:] = pred_val_y\n",
    "#     cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "# print(\"cv scores : \", cv_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_xgb = do(train_df,test_df,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.DataFrame(model.predict(val_X))\n",
    "# # pred_full_test\n",
    "\n",
    "\n",
    "    \n",
    "# def getVal(df):\n",
    "#     values =[]\n",
    "#     idxes = []\n",
    "#     for i in range(df.shape[0]):\n",
    "#         idx = df.iloc[i].idxmax()\n",
    "#         value = df.loc[i][idx]\n",
    "#         if value < 0.5:\n",
    "#             idx = 0\n",
    "#         idxes.append(int(idx))\n",
    "#     return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df =pd.DataFrame((pred_full_testlgb+pred_full_test)/10 , columns = ['0' ,'1' , '2'] )\n",
    "# getVal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa =[]\n",
    "# for i in range(df.shape[0]):\n",
    "#     idx = df.iloc[i].idxmax()\n",
    "#     value = df.loc[i][idx]\n",
    "#     if value < 0.45:\n",
    "#         idx = 0\n",
    "#     aa.append(int(idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def getSubFile(pred_full_test):\n",
    "# out_df = pd.DataFrame(aa)\n",
    "# out_df.columns = ['label']\n",
    "# author_mapping_dict = {0:0, 1:1, 2:-1}\n",
    "# out_df['label'] = out_df['label'].map(author_mapping_dict)\n",
    "# out_df['ID'] = test['ID']\n",
    "# out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df[['ID' , 'label']].to_csv(\"sub_fe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.269676\n",
      "0:\tlearn: 0.9798249\ttotal: 85.1ms\tremaining: 25.4s\n",
      "1:\tlearn: 0.9098551\ttotal: 173ms\tremaining: 25.8s\n",
      "2:\tlearn: 0.8637474\ttotal: 251ms\tremaining: 24.9s\n",
      "3:\tlearn: 0.8341343\ttotal: 325ms\tremaining: 24s\n",
      "4:\tlearn: 0.8136953\ttotal: 399ms\tremaining: 23.6s\n",
      "5:\tlearn: 0.8002022\ttotal: 488ms\tremaining: 23.9s\n",
      "6:\tlearn: 0.7904638\ttotal: 581ms\tremaining: 24.3s\n",
      "7:\tlearn: 0.7838308\ttotal: 668ms\tremaining: 24.4s\n",
      "8:\tlearn: 0.7800426\ttotal: 753ms\tremaining: 24.3s\n",
      "9:\tlearn: 0.7766756\ttotal: 856ms\tremaining: 24.8s\n",
      "10:\tlearn: 0.7743599\ttotal: 975ms\tremaining: 25.6s\n",
      "11:\tlearn: 0.7733435\ttotal: 1.08s\tremaining: 26s\n",
      "12:\tlearn: 0.7724777\ttotal: 1.14s\tremaining: 25.3s\n",
      "13:\tlearn: 0.7712363\ttotal: 1.2s\tremaining: 24.6s\n",
      "14:\tlearn: 0.7704989\ttotal: 1.28s\tremaining: 24.4s\n",
      "15:\tlearn: 0.7696014\ttotal: 1.33s\tremaining: 23.6s\n",
      "16:\tlearn: 0.7693162\ttotal: 1.37s\tremaining: 22.8s\n",
      "17:\tlearn: 0.7689336\ttotal: 1.43s\tremaining: 22.4s\n",
      "18:\tlearn: 0.7683491\ttotal: 1.51s\tremaining: 22.3s\n",
      "19:\tlearn: 0.7676921\ttotal: 1.55s\tremaining: 21.7s\n",
      "20:\tlearn: 0.7673593\ttotal: 1.59s\tremaining: 21.2s\n",
      "21:\tlearn: 0.7670656\ttotal: 1.65s\tremaining: 20.9s\n",
      "22:\tlearn: 0.7667467\ttotal: 1.72s\tremaining: 20.7s\n",
      "23:\tlearn: 0.7664633\ttotal: 1.82s\tremaining: 20.9s\n",
      "24:\tlearn: 0.7662054\ttotal: 1.88s\tremaining: 20.7s\n",
      "25:\tlearn: 0.7659117\ttotal: 1.96s\tremaining: 20.7s\n",
      "26:\tlearn: 0.7656997\ttotal: 2.04s\tremaining: 20.7s\n",
      "27:\tlearn: 0.7655246\ttotal: 2.13s\tremaining: 20.7s\n",
      "28:\tlearn: 0.7654225\ttotal: 2.2s\tremaining: 20.5s\n",
      "29:\tlearn: 0.7649819\ttotal: 2.28s\tremaining: 20.5s\n",
      "30:\tlearn: 0.7646990\ttotal: 2.32s\tremaining: 20.2s\n",
      "31:\tlearn: 0.7643593\ttotal: 2.41s\tremaining: 20.2s\n",
      "32:\tlearn: 0.7642030\ttotal: 2.5s\tremaining: 20.2s\n",
      "33:\tlearn: 0.7641306\ttotal: 2.53s\tremaining: 19.8s\n",
      "34:\tlearn: 0.7640670\ttotal: 2.57s\tremaining: 19.5s\n",
      "35:\tlearn: 0.7637503\ttotal: 2.61s\tremaining: 19.2s\n",
      "36:\tlearn: 0.7636951\ttotal: 2.68s\tremaining: 19.1s\n",
      "37:\tlearn: 0.7632004\ttotal: 2.78s\tremaining: 19.1s\n",
      "38:\tlearn: 0.7627692\ttotal: 2.85s\tremaining: 19.1s\n",
      "39:\tlearn: 0.7626839\ttotal: 2.93s\tremaining: 19.1s\n",
      "40:\tlearn: 0.7625844\ttotal: 3.01s\tremaining: 19s\n",
      "41:\tlearn: 0.7623903\ttotal: 3.12s\tremaining: 19.2s\n",
      "42:\tlearn: 0.7619951\ttotal: 3.21s\tremaining: 19.2s\n",
      "43:\tlearn: 0.7617814\ttotal: 3.29s\tremaining: 19.2s\n",
      "44:\tlearn: 0.7616665\ttotal: 3.37s\tremaining: 19.1s\n",
      "45:\tlearn: 0.7615167\ttotal: 3.45s\tremaining: 19s\n",
      "46:\tlearn: 0.7612503\ttotal: 3.52s\tremaining: 19s\n",
      "47:\tlearn: 0.7607878\ttotal: 3.62s\tremaining: 19s\n",
      "48:\tlearn: 0.7605791\ttotal: 3.69s\tremaining: 18.9s\n",
      "49:\tlearn: 0.7601906\ttotal: 3.77s\tremaining: 18.9s\n",
      "50:\tlearn: 0.7600070\ttotal: 3.83s\tremaining: 18.7s\n",
      "51:\tlearn: 0.7596037\ttotal: 3.92s\tremaining: 18.7s\n",
      "52:\tlearn: 0.7593609\ttotal: 4s\tremaining: 18.6s\n",
      "53:\tlearn: 0.7590895\ttotal: 4.08s\tremaining: 18.6s\n",
      "54:\tlearn: 0.7588973\ttotal: 4.16s\tremaining: 18.5s\n",
      "55:\tlearn: 0.7587826\ttotal: 4.23s\tremaining: 18.4s\n",
      "56:\tlearn: 0.7585665\ttotal: 4.31s\tremaining: 18.4s\n",
      "57:\tlearn: 0.7583912\ttotal: 4.39s\tremaining: 18.3s\n",
      "58:\tlearn: 0.7581757\ttotal: 4.46s\tremaining: 18.2s\n",
      "59:\tlearn: 0.7578504\ttotal: 4.54s\tremaining: 18.2s\n",
      "60:\tlearn: 0.7576381\ttotal: 4.62s\tremaining: 18.1s\n",
      "61:\tlearn: 0.7575155\ttotal: 4.69s\tremaining: 18s\n",
      "62:\tlearn: 0.7574124\ttotal: 4.75s\tremaining: 17.9s\n",
      "63:\tlearn: 0.7572183\ttotal: 4.79s\tremaining: 17.7s\n",
      "64:\tlearn: 0.7568205\ttotal: 4.86s\tremaining: 17.6s\n",
      "65:\tlearn: 0.7566379\ttotal: 4.94s\tremaining: 17.5s\n",
      "66:\tlearn: 0.7563632\ttotal: 5.03s\tremaining: 17.5s\n",
      "67:\tlearn: 0.7561879\ttotal: 5.1s\tremaining: 17.4s\n",
      "68:\tlearn: 0.7558660\ttotal: 5.19s\tremaining: 17.4s\n",
      "69:\tlearn: 0.7556076\ttotal: 5.26s\tremaining: 17.3s\n",
      "70:\tlearn: 0.7553696\ttotal: 5.37s\tremaining: 17.3s\n",
      "71:\tlearn: 0.7551237\ttotal: 5.45s\tremaining: 17.3s\n",
      "72:\tlearn: 0.7550023\ttotal: 5.52s\tremaining: 17.2s\n",
      "73:\tlearn: 0.7548334\ttotal: 5.61s\tremaining: 17.1s\n",
      "74:\tlearn: 0.7547196\ttotal: 5.68s\tremaining: 17s\n",
      "75:\tlearn: 0.7544981\ttotal: 5.74s\tremaining: 16.9s\n",
      "76:\tlearn: 0.7542723\ttotal: 5.78s\tremaining: 16.8s\n",
      "77:\tlearn: 0.7540692\ttotal: 5.85s\tremaining: 16.6s\n",
      "78:\tlearn: 0.7538096\ttotal: 5.93s\tremaining: 16.6s\n",
      "79:\tlearn: 0.7537519\ttotal: 6s\tremaining: 16.5s\n",
      "80:\tlearn: 0.7535227\ttotal: 6.09s\tremaining: 16.5s\n",
      "81:\tlearn: 0.7534080\ttotal: 6.16s\tremaining: 16.4s\n",
      "82:\tlearn: 0.7532204\ttotal: 6.23s\tremaining: 16.3s\n",
      "83:\tlearn: 0.7530031\ttotal: 6.27s\tremaining: 16.1s\n",
      "84:\tlearn: 0.7528721\ttotal: 6.34s\tremaining: 16s\n",
      "85:\tlearn: 0.7526994\ttotal: 6.41s\tremaining: 15.9s\n",
      "86:\tlearn: 0.7525447\ttotal: 6.49s\tremaining: 15.9s\n",
      "87:\tlearn: 0.7524531\ttotal: 6.57s\tremaining: 15.8s\n",
      "88:\tlearn: 0.7522267\ttotal: 6.66s\tremaining: 15.8s\n",
      "89:\tlearn: 0.7520280\ttotal: 6.73s\tremaining: 15.7s\n",
      "90:\tlearn: 0.7518847\ttotal: 6.77s\tremaining: 15.6s\n",
      "91:\tlearn: 0.7517676\ttotal: 6.85s\tremaining: 15.5s\n",
      "92:\tlearn: 0.7516938\ttotal: 6.91s\tremaining: 15.4s\n",
      "93:\tlearn: 0.7514888\ttotal: 6.95s\tremaining: 15.2s\n",
      "94:\tlearn: 0.7514390\ttotal: 7s\tremaining: 15.1s\n",
      "95:\tlearn: 0.7512064\ttotal: 7.09s\tremaining: 15.1s\n",
      "96:\tlearn: 0.7510830\ttotal: 7.17s\tremaining: 15s\n",
      "97:\tlearn: 0.7509516\ttotal: 7.25s\tremaining: 14.9s\n",
      "98:\tlearn: 0.7508135\ttotal: 7.32s\tremaining: 14.9s\n",
      "99:\tlearn: 0.7507193\ttotal: 7.38s\tremaining: 14.8s\n",
      "100:\tlearn: 0.7506337\ttotal: 7.42s\tremaining: 14.6s\n",
      "101:\tlearn: 0.7504928\ttotal: 7.48s\tremaining: 14.5s\n",
      "102:\tlearn: 0.7503892\ttotal: 7.55s\tremaining: 14.4s\n",
      "103:\tlearn: 0.7503032\ttotal: 7.62s\tremaining: 14.4s\n",
      "104:\tlearn: 0.7502422\ttotal: 7.68s\tremaining: 14.3s\n",
      "105:\tlearn: 0.7500712\ttotal: 7.76s\tremaining: 14.2s\n",
      "106:\tlearn: 0.7499867\ttotal: 7.84s\tremaining: 14.1s\n",
      "107:\tlearn: 0.7499074\ttotal: 7.9s\tremaining: 14.1s\n",
      "108:\tlearn: 0.7497368\ttotal: 8s\tremaining: 14s\n",
      "109:\tlearn: 0.7495253\ttotal: 8.09s\tremaining: 14s\n",
      "110:\tlearn: 0.7493376\ttotal: 8.18s\tremaining: 13.9s\n",
      "111:\tlearn: 0.7491350\ttotal: 8.29s\tremaining: 13.9s\n",
      "112:\tlearn: 0.7490498\ttotal: 8.36s\tremaining: 13.8s\n",
      "113:\tlearn: 0.7489070\ttotal: 8.45s\tremaining: 13.8s\n",
      "114:\tlearn: 0.7487290\ttotal: 8.53s\tremaining: 13.7s\n",
      "115:\tlearn: 0.7486078\ttotal: 8.61s\tremaining: 13.7s\n",
      "116:\tlearn: 0.7485274\ttotal: 8.7s\tremaining: 13.6s\n",
      "117:\tlearn: 0.7483914\ttotal: 8.78s\tremaining: 13.5s\n",
      "118:\tlearn: 0.7482271\ttotal: 8.87s\tremaining: 13.5s\n",
      "119:\tlearn: 0.7480743\ttotal: 8.95s\tremaining: 13.4s\n",
      "120:\tlearn: 0.7478927\ttotal: 9.03s\tremaining: 13.4s\n",
      "121:\tlearn: 0.7478091\ttotal: 9.11s\tremaining: 13.3s\n",
      "122:\tlearn: 0.7476807\ttotal: 9.2s\tremaining: 13.2s\n",
      "123:\tlearn: 0.7475900\ttotal: 9.27s\tremaining: 13.2s\n",
      "124:\tlearn: 0.7473692\ttotal: 9.36s\tremaining: 13.1s\n",
      "125:\tlearn: 0.7472907\ttotal: 9.44s\tremaining: 13s\n",
      "126:\tlearn: 0.7471195\ttotal: 9.52s\tremaining: 13s\n",
      "127:\tlearn: 0.7470410\ttotal: 9.59s\tremaining: 12.9s\n",
      "128:\tlearn: 0.7468641\ttotal: 9.66s\tremaining: 12.8s\n",
      "129:\tlearn: 0.7467028\ttotal: 9.74s\tremaining: 12.7s\n",
      "130:\tlearn: 0.7464780\ttotal: 9.83s\tremaining: 12.7s\n",
      "131:\tlearn: 0.7463583\ttotal: 9.88s\tremaining: 12.6s\n",
      "132:\tlearn: 0.7462823\ttotal: 10s\tremaining: 12.6s\n",
      "133:\tlearn: 0.7460785\ttotal: 10.1s\tremaining: 12.5s\n",
      "134:\tlearn: 0.7459961\ttotal: 10.2s\tremaining: 12.5s\n",
      "135:\tlearn: 0.7458407\ttotal: 10.3s\tremaining: 12.4s\n",
      "136:\tlearn: 0.7457281\ttotal: 10.4s\tremaining: 12.4s\n",
      "137:\tlearn: 0.7456219\ttotal: 10.5s\tremaining: 12.4s\n",
      "138:\tlearn: 0.7455321\ttotal: 10.6s\tremaining: 12.3s\n",
      "139:\tlearn: 0.7452914\ttotal: 10.7s\tremaining: 12.2s\n",
      "140:\tlearn: 0.7450883\ttotal: 10.8s\tremaining: 12.2s\n",
      "141:\tlearn: 0.7448810\ttotal: 10.9s\tremaining: 12.1s\n",
      "142:\tlearn: 0.7448089\ttotal: 10.9s\tremaining: 12s\n",
      "143:\tlearn: 0.7446874\ttotal: 11s\tremaining: 11.9s\n",
      "144:\tlearn: 0.7445298\ttotal: 11s\tremaining: 11.8s\n",
      "145:\tlearn: 0.7443986\ttotal: 11.1s\tremaining: 11.7s\n",
      "146:\tlearn: 0.7442680\ttotal: 11.2s\tremaining: 11.6s\n",
      "147:\tlearn: 0.7441819\ttotal: 11.2s\tremaining: 11.5s\n",
      "148:\tlearn: 0.7439636\ttotal: 11.3s\tremaining: 11.4s\n",
      "149:\tlearn: 0.7438248\ttotal: 11.4s\tremaining: 11.4s\n",
      "150:\tlearn: 0.7436647\ttotal: 11.4s\tremaining: 11.3s\n",
      "151:\tlearn: 0.7435000\ttotal: 11.5s\tremaining: 11.2s\n",
      "152:\tlearn: 0.7434048\ttotal: 11.6s\tremaining: 11.1s\n",
      "153:\tlearn: 0.7432569\ttotal: 11.6s\tremaining: 11s\n",
      "154:\tlearn: 0.7430864\ttotal: 11.7s\tremaining: 11s\n",
      "155:\tlearn: 0.7428445\ttotal: 11.8s\tremaining: 10.9s\n",
      "156:\tlearn: 0.7427821\ttotal: 11.9s\tremaining: 10.8s\n",
      "157:\tlearn: 0.7426940\ttotal: 11.9s\tremaining: 10.7s\n",
      "158:\tlearn: 0.7425783\ttotal: 12s\tremaining: 10.6s\n",
      "159:\tlearn: 0.7424336\ttotal: 12s\tremaining: 10.5s\n",
      "160:\tlearn: 0.7422722\ttotal: 12.1s\tremaining: 10.4s\n",
      "161:\tlearn: 0.7421643\ttotal: 12.1s\tremaining: 10.3s\n",
      "162:\tlearn: 0.7419976\ttotal: 12.2s\tremaining: 10.3s\n",
      "163:\tlearn: 0.7418252\ttotal: 12.3s\tremaining: 10.2s\n",
      "164:\tlearn: 0.7416583\ttotal: 12.4s\tremaining: 10.1s\n",
      "165:\tlearn: 0.7415107\ttotal: 12.4s\tremaining: 10s\n",
      "166:\tlearn: 0.7414493\ttotal: 12.5s\tremaining: 9.93s\n",
      "167:\tlearn: 0.7413874\ttotal: 12.5s\tremaining: 9.85s\n",
      "168:\tlearn: 0.7412853\ttotal: 12.6s\tremaining: 9.77s\n",
      "169:\tlearn: 0.7412403\ttotal: 12.6s\tremaining: 9.67s\n",
      "170:\tlearn: 0.7411533\ttotal: 12.7s\tremaining: 9.59s\n",
      "171:\tlearn: 0.7410445\ttotal: 12.8s\tremaining: 9.53s\n",
      "172:\tlearn: 0.7408713\ttotal: 12.9s\tremaining: 9.44s\n",
      "173:\tlearn: 0.7408136\ttotal: 12.9s\tremaining: 9.34s\n",
      "174:\tlearn: 0.7407014\ttotal: 13s\tremaining: 9.25s\n",
      "175:\tlearn: 0.7404675\ttotal: 13s\tremaining: 9.19s\n",
      "176:\tlearn: 0.7403340\ttotal: 13.1s\tremaining: 9.09s\n",
      "177:\tlearn: 0.7402407\ttotal: 13.2s\tremaining: 9.02s\n",
      "178:\tlearn: 0.7401430\ttotal: 13.2s\tremaining: 8.95s\n",
      "179:\tlearn: 0.7400835\ttotal: 13.3s\tremaining: 8.88s\n",
      "180:\tlearn: 0.7399843\ttotal: 13.4s\tremaining: 8.78s\n",
      "181:\tlearn: 0.7398573\ttotal: 13.4s\tremaining: 8.71s\n",
      "182:\tlearn: 0.7397211\ttotal: 13.5s\tremaining: 8.64s\n",
      "183:\tlearn: 0.7395737\ttotal: 13.6s\tremaining: 8.55s\n",
      "184:\tlearn: 0.7395169\ttotal: 13.6s\tremaining: 8.46s\n",
      "185:\tlearn: 0.7394063\ttotal: 13.7s\tremaining: 8.38s\n",
      "186:\tlearn: 0.7393335\ttotal: 13.7s\tremaining: 8.31s\n",
      "187:\tlearn: 0.7392717\ttotal: 13.8s\tremaining: 8.23s\n",
      "188:\tlearn: 0.7391157\ttotal: 13.9s\tremaining: 8.14s\n",
      "189:\tlearn: 0.7390180\ttotal: 13.9s\tremaining: 8.07s\n",
      "190:\tlearn: 0.7389418\ttotal: 14s\tremaining: 8s\n",
      "191:\tlearn: 0.7387897\ttotal: 14.1s\tremaining: 7.91s\n",
      "192:\tlearn: 0.7387344\ttotal: 14.1s\tremaining: 7.82s\n",
      "193:\tlearn: 0.7386230\ttotal: 14.1s\tremaining: 7.73s\n",
      "194:\tlearn: 0.7385010\ttotal: 14.2s\tremaining: 7.67s\n",
      "195:\tlearn: 0.7384274\ttotal: 14.3s\tremaining: 7.6s\n",
      "196:\tlearn: 0.7382268\ttotal: 14.4s\tremaining: 7.52s\n",
      "197:\tlearn: 0.7380667\ttotal: 14.5s\tremaining: 7.45s\n",
      "198:\tlearn: 0.7380228\ttotal: 14.5s\tremaining: 7.36s\n",
      "199:\tlearn: 0.7379530\ttotal: 14.5s\tremaining: 7.27s\n",
      "200:\tlearn: 0.7378635\ttotal: 14.6s\tremaining: 7.19s\n",
      "201:\tlearn: 0.7377573\ttotal: 14.7s\tremaining: 7.13s\n",
      "202:\tlearn: 0.7376560\ttotal: 14.7s\tremaining: 7.04s\n",
      "203:\tlearn: 0.7375574\ttotal: 14.8s\tremaining: 6.96s\n",
      "204:\tlearn: 0.7375079\ttotal: 14.8s\tremaining: 6.88s\n",
      "205:\tlearn: 0.7374327\ttotal: 14.9s\tremaining: 6.81s\n",
      "206:\tlearn: 0.7372944\ttotal: 15s\tremaining: 6.73s\n",
      "207:\tlearn: 0.7371268\ttotal: 15s\tremaining: 6.65s\n",
      "208:\tlearn: 0.7369859\ttotal: 15.1s\tremaining: 6.58s\n",
      "209:\tlearn: 0.7368498\ttotal: 15.2s\tremaining: 6.51s\n",
      "210:\tlearn: 0.7367964\ttotal: 15.2s\tremaining: 6.43s\n",
      "211:\tlearn: 0.7366084\ttotal: 15.3s\tremaining: 6.35s\n",
      "212:\tlearn: 0.7365597\ttotal: 15.4s\tremaining: 6.27s\n",
      "213:\tlearn: 0.7364127\ttotal: 15.4s\tremaining: 6.21s\n",
      "214:\tlearn: 0.7363609\ttotal: 15.5s\tremaining: 6.12s\n",
      "215:\tlearn: 0.7362163\ttotal: 15.5s\tremaining: 6.04s\n",
      "216:\tlearn: 0.7360687\ttotal: 15.6s\tremaining: 5.96s\n",
      "217:\tlearn: 0.7359459\ttotal: 15.7s\tremaining: 5.9s\n",
      "218:\tlearn: 0.7358340\ttotal: 15.7s\tremaining: 5.82s\n",
      "219:\tlearn: 0.7356996\ttotal: 15.8s\tremaining: 5.73s\n",
      "220:\tlearn: 0.7355815\ttotal: 15.8s\tremaining: 5.66s\n",
      "221:\tlearn: 0.7354457\ttotal: 15.9s\tremaining: 5.59s\n",
      "222:\tlearn: 0.7353349\ttotal: 16s\tremaining: 5.51s\n",
      "223:\tlearn: 0.7352675\ttotal: 16s\tremaining: 5.43s\n",
      "224:\tlearn: 0.7351480\ttotal: 16.1s\tremaining: 5.35s\n",
      "225:\tlearn: 0.7350504\ttotal: 16.1s\tremaining: 5.28s\n",
      "226:\tlearn: 0.7349049\ttotal: 16.2s\tremaining: 5.21s\n",
      "227:\tlearn: 0.7348215\ttotal: 16.2s\tremaining: 5.13s\n",
      "228:\tlearn: 0.7347729\ttotal: 16.3s\tremaining: 5.05s\n",
      "229:\tlearn: 0.7346902\ttotal: 16.4s\tremaining: 4.99s\n",
      "230:\tlearn: 0.7346220\ttotal: 16.4s\tremaining: 4.91s\n",
      "231:\tlearn: 0.7345435\ttotal: 16.5s\tremaining: 4.83s\n",
      "232:\tlearn: 0.7344363\ttotal: 16.5s\tremaining: 4.75s\n",
      "233:\tlearn: 0.7343721\ttotal: 16.6s\tremaining: 4.68s\n",
      "234:\tlearn: 0.7342801\ttotal: 16.7s\tremaining: 4.61s\n",
      "235:\tlearn: 0.7341192\ttotal: 16.7s\tremaining: 4.53s\n",
      "236:\tlearn: 0.7340380\ttotal: 16.8s\tremaining: 4.46s\n",
      "237:\tlearn: 0.7338806\ttotal: 16.9s\tremaining: 4.39s\n",
      "238:\tlearn: 0.7337933\ttotal: 16.9s\tremaining: 4.31s\n",
      "239:\tlearn: 0.7337099\ttotal: 16.9s\tremaining: 4.23s\n",
      "240:\tlearn: 0.7336297\ttotal: 17s\tremaining: 4.16s\n",
      "241:\tlearn: 0.7334940\ttotal: 17.1s\tremaining: 4.09s\n",
      "242:\tlearn: 0.7334008\ttotal: 17.1s\tremaining: 4.02s\n",
      "243:\tlearn: 0.7332411\ttotal: 17.2s\tremaining: 3.94s\n",
      "244:\tlearn: 0.7331260\ttotal: 17.3s\tremaining: 3.87s\n",
      "245:\tlearn: 0.7329474\ttotal: 17.3s\tremaining: 3.81s\n",
      "246:\tlearn: 0.7328035\ttotal: 17.4s\tremaining: 3.73s\n",
      "247:\tlearn: 0.7327106\ttotal: 17.4s\tremaining: 3.66s\n",
      "248:\tlearn: 0.7326891\ttotal: 17.5s\tremaining: 3.58s\n",
      "249:\tlearn: 0.7326452\ttotal: 17.6s\tremaining: 3.51s\n",
      "250:\tlearn: 0.7325677\ttotal: 17.6s\tremaining: 3.44s\n",
      "251:\tlearn: 0.7325397\ttotal: 17.7s\tremaining: 3.37s\n",
      "252:\tlearn: 0.7324561\ttotal: 17.7s\tremaining: 3.3s\n",
      "253:\tlearn: 0.7323807\ttotal: 17.8s\tremaining: 3.23s\n",
      "254:\tlearn: 0.7323260\ttotal: 17.9s\tremaining: 3.15s\n",
      "255:\tlearn: 0.7321952\ttotal: 17.9s\tremaining: 3.08s\n",
      "256:\tlearn: 0.7320854\ttotal: 18s\tremaining: 3.01s\n",
      "257:\tlearn: 0.7319636\ttotal: 18.1s\tremaining: 2.94s\n",
      "258:\tlearn: 0.7318685\ttotal: 18.1s\tremaining: 2.87s\n",
      "259:\tlearn: 0.7317836\ttotal: 18.2s\tremaining: 2.79s\n",
      "260:\tlearn: 0.7316888\ttotal: 18.3s\tremaining: 2.73s\n",
      "261:\tlearn: 0.7315577\ttotal: 18.4s\tremaining: 2.66s\n",
      "262:\tlearn: 0.7314915\ttotal: 18.4s\tremaining: 2.59s\n",
      "263:\tlearn: 0.7313759\ttotal: 18.5s\tremaining: 2.52s\n",
      "264:\tlearn: 0.7312984\ttotal: 18.5s\tremaining: 2.45s\n",
      "265:\tlearn: 0.7311676\ttotal: 18.6s\tremaining: 2.38s\n",
      "266:\tlearn: 0.7310398\ttotal: 18.7s\tremaining: 2.31s\n",
      "267:\tlearn: 0.7309501\ttotal: 18.8s\tremaining: 2.24s\n",
      "268:\tlearn: 0.7308593\ttotal: 18.8s\tremaining: 2.17s\n",
      "269:\tlearn: 0.7307638\ttotal: 18.9s\tremaining: 2.1s\n",
      "270:\tlearn: 0.7306330\ttotal: 19s\tremaining: 2.03s\n",
      "271:\tlearn: 0.7305479\ttotal: 19s\tremaining: 1.96s\n",
      "272:\tlearn: 0.7304593\ttotal: 19.1s\tremaining: 1.89s\n",
      "273:\tlearn: 0.7303590\ttotal: 19.1s\tremaining: 1.81s\n",
      "274:\tlearn: 0.7302224\ttotal: 19.2s\tremaining: 1.74s\n",
      "275:\tlearn: 0.7300281\ttotal: 19.3s\tremaining: 1.67s\n",
      "276:\tlearn: 0.7299044\ttotal: 19.3s\tremaining: 1.6s\n",
      "277:\tlearn: 0.7298231\ttotal: 19.4s\tremaining: 1.53s\n",
      "278:\tlearn: 0.7297007\ttotal: 19.4s\tremaining: 1.46s\n",
      "279:\tlearn: 0.7296218\ttotal: 19.5s\tremaining: 1.39s\n",
      "280:\tlearn: 0.7295470\ttotal: 19.6s\tremaining: 1.32s\n",
      "281:\tlearn: 0.7295119\ttotal: 19.6s\tremaining: 1.25s\n",
      "282:\tlearn: 0.7293497\ttotal: 19.7s\tremaining: 1.18s\n",
      "283:\tlearn: 0.7291810\ttotal: 19.7s\tremaining: 1.11s\n",
      "284:\tlearn: 0.7290840\ttotal: 19.8s\tremaining: 1.04s\n",
      "285:\tlearn: 0.7289731\ttotal: 19.9s\tremaining: 972ms\n",
      "286:\tlearn: 0.7287990\ttotal: 19.9s\tremaining: 903ms\n",
      "287:\tlearn: 0.7286728\ttotal: 20s\tremaining: 834ms\n",
      "288:\tlearn: 0.7286034\ttotal: 20s\tremaining: 763ms\n",
      "289:\tlearn: 0.7284849\ttotal: 20.1s\tremaining: 694ms\n",
      "290:\tlearn: 0.7283956\ttotal: 20.2s\tremaining: 625ms\n",
      "291:\tlearn: 0.7283041\ttotal: 20.3s\tremaining: 555ms\n",
      "292:\tlearn: 0.7282437\ttotal: 20.3s\tremaining: 485ms\n",
      "293:\tlearn: 0.7281050\ttotal: 20.4s\tremaining: 415ms\n",
      "294:\tlearn: 0.7279894\ttotal: 20.4s\tremaining: 346ms\n",
      "295:\tlearn: 0.7278734\ttotal: 20.5s\tremaining: 277ms\n",
      "296:\tlearn: 0.7278051\ttotal: 20.5s\tremaining: 207ms\n",
      "297:\tlearn: 0.7277275\ttotal: 20.6s\tremaining: 138ms\n",
      "298:\tlearn: 0.7276461\ttotal: 20.7s\tremaining: 69.1ms\n",
      "299:\tlearn: 0.7275685\ttotal: 20.7s\tremaining: 0us\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 3, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-865eeb323a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpred_full_testcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_full_testcat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpred_test_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpred_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_val_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_val_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cv scores : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2226\u001b[0;31m             raise ValueError(\"y_true and y_pred contain different number of \"\n\u001b[0m\u001b[1;32m   2227\u001b[0m                              \u001b[0;34m\"classes {0}, {1}. Please provide the true \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m                              \u001b[0;34m\"labels explicitly through the labels argument. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 3, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 2]"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=7, shuffle=True, random_state=100)\n",
    "cv_scores = []\n",
    "pred_full_testcat = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, cat_clf = runCat(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_full_testcat = pred_full_testcat + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, getVal(pd.DataFrame(pred_val_y))))\n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=100)\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, model = runLog(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, getVal(pd.DataFrame(pred_val_y))))\n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # we can add class_weight='balanced' to add panalize mistake\n",
    "# svc_model = SVC(class_weight='balanced', probability=True)\n",
    "\n",
    "# svc_model.fit(x_train, y_train)\n",
    "\n",
    "# svc_predict = svc_model.predict(x_test)# check performance\n",
    "# print('ROCAUC score:',roc_auc_score(y_test, svc_predict))\n",
    "# print('Accuracy score:',accuracy_score(y_test, svc_predict))\n",
    "# print('F1 score:',f1_score(y_test, svc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # metrics.accuracy_score(val_y , lgb_clf.predict(val_X))\n",
    "# from nltk.classify.textcat import TextCat\n",
    "\n",
    "# sc = TextCat()\n",
    "\n",
    "# sc.guess_language(\"kula kwa macho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv scores :  [0.7819585602438411, 0.7915709068289086, 0.7864753527249269, 0.8045947995127501, 0.8020220095221116, 0.7956601076868789, 0.7970279317670658, 0.8075372864374825, 0.8031619907047877, 0.7958514689956935]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=100)\n",
    "cv_scores = []\n",
    "pred_full_testlgb = 0\n",
    "pred_train = np.zeros([train_df.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y,lgb_clf = runlgb(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_full_testlgb = pred_full_testlgb + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:16:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:16:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "cv scores :  [0.8064916834429895, 0.814692941154193, 0.820484485956586]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=100)\n",
    "cv_scores = []\n",
    "pred_full_testx = 0\n",
    "pred_trainx = np.zeros([train_df.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, model_xgb = runxgb(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_full_testx = pred_full_testx + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5896369948142116"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(val_y , model_xgb.predict(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Plot the important variables ###\n",
    "# fig, ax = plt.subplots(figsize=(12,12))\n",
    "# xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame((pred_full_testlgb/10 + pred_full_testcat/7 + result_xgb)/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mycat = pd.DataFrame(pred_full_testcat/7)\n",
    "# mylgb = pd.DataFrame(pred_full_testlgb/10)\n",
    "myxgb1 = pd.DataFrame(result_xgb)\n",
    "# myxgb2 = pd.DataFrame(pred_full_testx)\n",
    "# mycom1 = pd.DataFrame((pred_full_testlgb/10 + pred_full_testcat/7 + result_xgb)/3)\n",
    "# mycom2 = pd.DataFrame((pred_full_testcat/7 + result_xgb)/2)\n",
    "# mycom3 = pd.DataFrame((pred_full_testlgb/10 + result_xgb)/2)\n",
    "# mycom4 = pd.DataFrame((pred_full_testlgb/10 + pred_full_testcat/7 + result_xgb + myxgb2)/4)\n",
    "# mycom5 = pd.DataFrame((pred_full_testlgb/10 + pred_full_testcat/7)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014949</td>\n",
       "      <td>0.390923</td>\n",
       "      <td>0.594129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.100109</td>\n",
       "      <td>0.883598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.988112</td>\n",
       "      <td>0.011313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049375</td>\n",
       "      <td>0.507899</td>\n",
       "      <td>0.442726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.941686</td>\n",
       "      <td>0.055533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.150360</td>\n",
       "      <td>0.379257</td>\n",
       "      <td>0.470383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.955785</td>\n",
       "      <td>0.040805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.028068</td>\n",
       "      <td>0.400878</td>\n",
       "      <td>0.571054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.039173</td>\n",
       "      <td>0.957124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.954481</td>\n",
       "      <td>0.043453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2\n",
       "0      0.014949  0.390923  0.594129\n",
       "1      0.016293  0.100109  0.883598\n",
       "2      0.000575  0.988112  0.011313\n",
       "3      0.049375  0.507899  0.442726\n",
       "4      0.002781  0.941686  0.055533\n",
       "...         ...       ...       ...\n",
       "29995  0.150360  0.379257  0.470383\n",
       "29996  0.003410  0.955785  0.040805\n",
       "29997  0.028068  0.400878  0.571054\n",
       "29998  0.003703  0.039173  0.957124\n",
       "29999  0.002066  0.954481  0.043453\n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myxgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVal(df):\n",
    "    values =[]\n",
    "    idxes = []\n",
    "    for i in range(df.shape[0]):\n",
    "        idx = df.iloc[i].idxmax()\n",
    "        value = df.loc[i][idx]\n",
    "        if value < 0.5:\n",
    "            idx = 0\n",
    "        idxes.append(int(idx))\n",
    "    return idxes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_lgb = getVal(mylgb)\n",
    "v_xgb = getVal(myxgb1)\n",
    "# v_cat = getVal(mylgb)\n",
    "# v_xgb2 = getVal(myxgb2)\n",
    "# combined\n",
    "# v_1 = getVal(mycom1)\n",
    "# v_2 = getVal(mycom2)\n",
    "# v_3 = getVal(mycom3)\n",
    "# v_4 = getVal(mycom4)\n",
    "# v_5 = getVal(mycom5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(values):\n",
    "    # def getSubFile(pred_full_test):\n",
    "    out_df = pd.DataFrame(values)\n",
    "    out_df.columns = ['label']\n",
    "    author_mapping_dict = {0:0, 1:1, 2:-1}\n",
    "    out_df['label'] = out_df['label'].map(author_mapping_dict)\n",
    "    out_df['ID'] = test['ID']\n",
    "#     print(out_df.head())\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df[['ID' , 'label']].to_csv(\"sub_sm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# getFrame(v_lgb)[['ID' , 'label']].to_csv('lgb.csv' , index = False)\n",
    "getFrame(v_xgb)[['ID' , 'label']].to_csv('xgb.csv' , index = False)\n",
    "# getFrame(v_cat)[['ID' , 'label']].to_csv('cat.csv' , index = False)\n",
    "# getFrame(v_xgb2)[['ID' , 'label']].to_csv('xgb2.csv' , index = False)\n",
    "\n",
    "# # combines\n",
    "# getFrame(v_1)[['ID' , 'label']].to_csv('v1.csv' , index = False)\n",
    "# getFrame(v_2)[['ID' , 'label']].to_csv('v2.csv' , index = False)\n",
    "# getFrame(v_3)[['ID' , 'label']].to_csv('v3.csv' , index = False)\n",
    "# getFrame(v_4)[['ID' , 'label']].to_csv('v4.csv' , index = False)\n",
    "# getFrame(v_5)[['ID' , 'label']].to_csv('v5.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
